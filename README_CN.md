# MCP智能体平台

## 项目简介

这是一个基于多智能体架构的人机交互系统，集成了视觉识别、语音识别和语音合成等功能。系统由多个专门的智能体协同工作，实现了自然的人机交互体验。给大模型增加眼睛和耳朵和嘴巴！

## 系统架构

系统采用分布式多智能体架构，通过MCP（Multi-agent Communication Protocol）协议实现智能体间的高效通信和协作。

### 智能体

- **大脑智能体 (Brain Agent)**
  - 负责系统的核心决策和协调
  - 处理来自其他智能体的信息
  - 集成Ollama大模型API，实现多模态理解和生成
  - 管理智能体状态和任务调度

- **视觉智能体 (Eye Agent)**
  - 处理视觉输入
  - 实现人脸检测和识别
  - 支持实时视频流处理
  - 生成图像分析结果

- **听觉智能体 (Ear Agent)**
  - 处理音频输入
  - 实现语音识别
  - 支持实时语音流处理
  - 提供噪声抑制和信号增强

- **发声智能体 (Mouth Agent)**
  - 负责语音输出
  - 实现语音合成
  - 支持情感语音合成
  - 提供自然的语音交互体验

### 通信机制

系统采用基于WebSocket的实时通信机制，通过MCP协议实现智能体间的消息传递：

1. **消息类型**
   - 文本消息（TextMessage）
   - 图像消息（ImageMessage）
   - 音频消息（AudioMessage）
   - 命令消息（CommandMessage）
   - 状态消息（StatusMessage）

2. **消息路由**
   - 基于发送者和接收者ID的消息路由
   - 支持广播和点对点通信
   - 实现消息的可靠传递和确认机制

3. **状态管理**
   - 智能体状态实时监控
   - 系统资源动态分配
   - 任务队列优先级管理

### 技术原理

#### 人脸识别技术

系统采用深度学习模型实现人脸识别功能：

1. **人脸检测**
   - 使用MTCNN（Multi-task Cascaded Convolutional Networks）级联卷积神经网络
   - 通过P-Net、R-Net和O-Net三级网络实现人脸检测和关键点定位
   - 实时处理视频流，支持多人脸同时检测

2. **特征提取**
   - 采用FaceNet深度学习模型提取128维人脸特征向量
   - 使用Triplet Loss训练策略优化特征提取
   - 实现人脸对齐和归一化处理

3. **相似度计算**
   - 使用余弦相似度计算特征向量距离
   - 设定动态阈值进行身份匹配
   - 实现特征向量索引和快速检索

#### 语音处理技术

1. **语音识别**
   - 使用Wav2Vec预训练模型进行特征提取
   - 采用CTC（Connectionist Temporal Classification）解码算法
   - 集成中文语音识别模型，支持实时转写

2. **语音合成**
   - 基于FastSpeech2实现端到端语音合成
   - 使用HiFiGAN声码器生成高质量音频
   - 支持情感控制和语速调节

#### 多模态处理

1. **特征融合**
   - 实现视觉和语音特征的多模态融合
   - 使用Attention机制进行跨模态对齐
   - 支持多模态信息的协同理解

2. **上下文管理**
   - 维护多轮对话历史
   - 实现跨模态信息的关联分析
   - 动态更新对话状态

### 大模型集成

系统集成了Ollama大模型API，实现了多模态智能处理。系统根据不同任务类型配置相应的模型：

1. **模型配置**
   - 文本处理：使用qwen2模型
   - 图像处理：使用gemma3:4b模型，支持多模态处理
   - 音频处理：使用qwen2模型，temperature参数设为0.5

2. **功能实现**
   - **图像理解**
     - 场景分析和物体识别
     - 人脸特征提取和情感分析
     - 图像描述生成

   - **对话生成**
     - 上下文感知的对话管理
     - 多轮对话历史维护
     - 个性化回复生成

   - **多模态融合**
     - 图文结合的场景理解
     - 语音和文本的双向转换
     - 多模态信息的综合分析

3. **配置示例**
```python
# Ollama模型配置
OLLAMA_BASE_URL = "http://127.0.0.1:11434"

# 不同类型任务的模型配置
MODEL_CONFIG = {
    "text": {
        "model": "qwen2",  # 文本处理模型
        "params": {}
    },
    "image": {
        "model": "gemma3:4b",  # 图像处理模型
        "params": {},
        "multimodal": True
    },
    "audio": {
        "model": "qwen2",  # 音频处理模型
        "params": {"temperature": 0.5}
    }
}
```

### 核心功能

1. **人脸识别**
   - 实时人脸检测和识别
   - 人物信息数据库管理
   - 人脸特征提取和匹配
   - 陌生人识别和记录

2. **语音交互**
   - 中文语音识别
   - 语音合成输出
   - 实时语音对话
   - 情感语音合成

3. **Web界面**
   - 可视化机器人界面
   - 实时状态显示
   - 交互式控制面板
   - 系统监控仪表盘

## 安装说明

### 环境要求

- Python 3.10+
- Windows/Linux/MacOS

### 安装步骤

1. 克隆项目
```bash
git clone [repository-url]
cd mcpTest
```

2. 安装依赖
```bash
pip install -r requirements.txt
```

### 配置说明

在`config.py`中可以配置以下参数：

- 服务器配置
- 智能体参数
- 模型设置
- 语音识别参数

## 使用说明

### 启动系统

1. 运行主程序
```bash
python main.py
```

2. 访问Web界面
```
http://localhost:8070
```

### 功能使用

1. **人脸识别**
   - 系统会自动检测和识别摄像头中的人脸
   - 首次识别的人脸会被自动记录

2. **语音交互**
   - 系统支持中文语音识别
   - 可以通过语音与系统进行对话

## 技术栈

- **后端**
  - Python
  - FastAPI
  - WebSocket
  - OpenCV
  - SpeechRecognition
  - pyttsx3

- **前端**
  - HTML/CSS
  - JavaScript
  - WebSocket

## 目录结构

```
├── config.py           # 配置文件
├── main.py            # 主程序
├── requirements.txt   # 依赖清单
├── src/
│   ├── agents/       # 智能体实现
│   ├── brain/        # 大脑逻辑
│   ├── platform/     # 平台核心
│   ├── utils/        # 工具函数
│   └── web/          # Web服务
├── static/           # 静态资源
└── templates/        # 页面模板
```